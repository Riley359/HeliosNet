{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf3f1ff4",
   "metadata": {},
   "source": [
    "# Fire Risk Prediction Model Training\n",
    "This notebook creates a machine learning model to predict fire risk based on weather conditions.\n",
    "We'll use historical fire data and weather patterns to train a classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9b235d",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "Import the necessary libraries for data processing, machine learning, and model export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d661e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For ONNX export\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c61e6e",
   "metadata": {},
   "source": [
    "## Data Collection and Preparation\n",
    "Since we don't have access to real historical fire datasets in this environment, we'll create synthetic data that mimics realistic fire risk patterns based on weather conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b4c71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic fire risk dataset based on realistic weather patterns\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate 10000 samples\n",
    "n_samples = 10000\n",
    "\n",
    "# Weather features that influence fire risk\n",
    "data = {\n",
    "    'temperature': np.random.normal(75, 20, n_samples),  # Fahrenheit\n",
    "    'humidity': np.random.beta(2, 3, n_samples) * 100,   # Percentage 0-100\n",
    "    'wind_speed': np.random.exponential(8, n_samples),   # mph\n",
    "    'precipitation': np.random.exponential(0.1, n_samples),  # inches in last 7 days\n",
    "    'drought_index': np.random.beta(2, 5, n_samples) * 100,  # 0-100 scale\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Ensure realistic ranges\n",
    "df['temperature'] = np.clip(df['temperature'], 20, 120)\n",
    "df['humidity'] = np.clip(df['humidity'], 5, 95)\n",
    "df['wind_speed'] = np.clip(df['wind_speed'], 0, 50)\n",
    "df['precipitation'] = np.clip(df['precipitation'], 0, 5)\n",
    "df['drought_index'] = np.clip(df['drought_index'], 0, 100)\n",
    "\n",
    "# Create fire risk labels based on realistic conditions\n",
    "# High risk conditions: high temp, low humidity, high wind, low precipitation, high drought\n",
    "def calculate_fire_risk(row):\n",
    "    risk_score = 0\n",
    "    \n",
    "    # Temperature contribution (higher = more risk)\n",
    "    if row['temperature'] > 85:\n",
    "        risk_score += 2\n",
    "    elif row['temperature'] > 75:\n",
    "        risk_score += 1\n",
    "    \n",
    "    # Humidity contribution (lower = more risk)\n",
    "    if row['humidity'] < 20:\n",
    "        risk_score += 3\n",
    "    elif row['humidity'] < 40:\n",
    "        risk_score += 2\n",
    "    elif row['humidity'] < 60:\n",
    "        risk_score += 1\n",
    "    \n",
    "    # Wind speed contribution (higher = more risk)\n",
    "    if row['wind_speed'] > 20:\n",
    "        risk_score += 2\n",
    "    elif row['wind_speed'] > 10:\n",
    "        risk_score += 1\n",
    "    \n",
    "    # Precipitation contribution (lower = more risk)\n",
    "    if row['precipitation'] < 0.1:\n",
    "        risk_score += 2\n",
    "    elif row['precipitation'] < 0.5:\n",
    "        risk_score += 1\n",
    "    \n",
    "    # Drought index contribution (higher = more risk)\n",
    "    if row['drought_index'] > 70:\n",
    "        risk_score += 2\n",
    "    elif row['drought_index'] > 50:\n",
    "        risk_score += 1\n",
    "    \n",
    "    # Add some randomness to make it more realistic\n",
    "    risk_score += np.random.normal(0, 0.5)\n",
    "    \n",
    "    # Convert to binary classification (high risk = 1, low risk = 0)\n",
    "    return 1 if risk_score > 5 else 0\n",
    "\n",
    "df['fire_risk'] = df.apply(calculate_fire_risk, axis=1)\n",
    "\n",
    "print(f\"Dataset created with {len(df)} samples\")\n",
    "print(f\"Fire risk distribution:\")\n",
    "print(df['fire_risk'].value_counts())\n",
    "print(f\"High risk percentage: {df['fire_risk'].mean()*100:.1f}%\")\n",
    "\n",
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7fb1df",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "Let's analyze the relationships between weather features and fire risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a33b752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('Weather Features vs Fire Risk', fontsize=16)\n",
    "\n",
    "features = ['temperature', 'humidity', 'wind_speed', 'precipitation', 'drought_index']\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "    \n",
    "    # Box plot showing distribution by fire risk\n",
    "    df.boxplot(column=feature, by='fire_risk', ax=axes[row, col])\n",
    "    axes[row, col].set_title(f'{feature.replace(\"_\", \" \").title()}')\n",
    "    axes[row, col].set_xlabel('Fire Risk (0=Low, 1=High)')\n",
    "\n",
    "# Remove the empty subplot\n",
    "fig.delaxes(axes[1, 2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dbeb87",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "Train a Random Forest classifier to predict fire risk based on weather conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75254acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = df[['temperature', 'humidity', 'wind_speed', 'precipitation', 'drought_index']]\n",
    "y = df['fire_risk']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "\n",
    "# Scale the features for better model performance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "y_pred_proba = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['feature'], feature_importance['importance'])\n",
    "plt.title('Feature Importance for Fire Risk Prediction')\n",
    "plt.xlabel('Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef84d2a5",
   "metadata": {},
   "source": [
    "## Export Model to ONNX Format\n",
    "Convert the trained model to ONNX format for use in the Rust backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3e1f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline that includes scaling and the model\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a pipeline with scaler and model\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('classifier', rf_model)\n",
    "])\n",
    "\n",
    "# Fit the pipeline (this just sets up the pipeline structure)\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Define the input type for ONNX conversion\n",
    "initial_type = [('float_input', FloatTensorType([None, 5]))]\n",
    "\n",
    "# Convert to ONNX\n",
    "onnx_model = convert_sklearn(pipeline, initial_types=initial_type)\n",
    "\n",
    "# Save the ONNX model\n",
    "with open('model.onnx', 'wb') as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "print(\"Model successfully exported to model.onnx\")\n",
    "\n",
    "# Test the exported model with a sample prediction\n",
    "sample_data = np.array([[85.0, 25.0, 15.0, 0.05, 75.0]])  # High risk conditions\n",
    "prediction = pipeline.predict_proba(sample_data)[0, 1]\n",
    "print(f\"\\nSample prediction (high risk conditions): {prediction:.3f}\")\n",
    "\n",
    "sample_data_low = np.array([[65.0, 70.0, 5.0, 2.0, 20.0]])  # Low risk conditions\n",
    "prediction_low = pipeline.predict_proba(sample_data_low)[0, 1]\n",
    "print(f\"Sample prediction (low risk conditions): {prediction_low:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08059f11",
   "metadata": {},
   "source": [
    "## Model Validation and Testing\n",
    "Test the model with various scenarios to ensure it behaves as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18b5d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test scenarios\n",
    "test_scenarios = {\n",
    "    'Extreme High Risk': [100, 10, 30, 0, 90],\n",
    "    'High Risk': [90, 20, 20, 0.1, 70],\n",
    "    'Moderate Risk': [75, 45, 10, 0.5, 50],\n",
    "    'Low Risk': [65, 65, 5, 1.5, 30],\n",
    "    'Very Low Risk': [50, 80, 2, 3.0, 10]\n",
    "}\n",
    "\n",
    "print(\"Model Validation - Test Scenarios:\")\n",
    "print(\"===================================\")\n",
    "print(f\"{'Scenario':<20} {'Temp':<6} {'Humid':<6} {'Wind':<6} {'Precip':<7} {'Drought':<7} {'Risk':<6}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for scenario_name, conditions in test_scenarios.items():\n",
    "    risk_prob = pipeline.predict_proba([conditions])[0, 1]\n",
    "    print(f\"{scenario_name:<20} {conditions[0]:<6.0f} {conditions[1]:<6.0f} {conditions[2]:<6.0f} {conditions[3]:<7.2f} {conditions[4]:<7.0f} {risk_prob:<6.3f}\")\n",
    "\n",
    "print(\"\\nModel ready for integration into Rust backend!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0918eb8c",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has successfully:\n",
    "\n",
    "1. **Created a synthetic dataset** that mimics realistic fire risk patterns based on weather conditions\n",
    "2. **Trained a Random Forest classifier** to predict fire risk from weather features\n",
    "3. **Exported the model to ONNX format** for integration with the Rust backend\n",
    "4. **Validated the model** with various test scenarios\n",
    "\n",
    "The model uses the following features:\n",
    "- Temperature (Â°F)\n",
    "- Humidity (%)\n",
    "- Wind Speed (mph)\n",
    "- Precipitation in last 7 days (inches)\n",
    "- Drought Index (0-100 scale)\n",
    "\n",
    "The exported `model.onnx` file can now be integrated into the Rust backend to provide real-time fire risk predictions based on current weather conditions.\n",
    "\n",
    "### Next Steps:\n",
    "1. Move the `model.onnx` file to the Rust project directory\n",
    "2. Add ONNX runtime dependencies to Cargo.toml\n",
    "3. Create the risk prediction module in Rust\n",
    "4. Implement the API endpoint for risk predictions\n",
    "5. Add frontend functionality for interactive risk checking"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
